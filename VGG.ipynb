{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG_3blocks_Patch=200_epoch=50.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsQB1PIBqC81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import platform\n",
        "import io\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import cm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xyso7Re5roFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyXlqalzsG8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_link=\"https://drive.google.com/open?id=1MHimMDZ7wlYvLsOilWmIqQnxRo4xLn8O\"\n",
        "test_link=\"https://drive.google.com/open?id=14aEt_3irPQ5MI8ZTFSzj17vwvar00QU0\"\n",
        "label_link=\"https://drive.google.com/open?id=18xt_fv9r_OpvtGg7f0axAZAgqD8q_sku\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BA2PupVtIAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getFile(link,pkl):\n",
        "    fluff, id = link.split('=')\n",
        "    downloaded = drive.CreateFile({'id':id})\n",
        "    if pkl is True:\n",
        "        downloaded.GetContentFile('file.pkl')\n",
        "        file=pd.read_pickle('file.pkl')\n",
        "        return file\n",
        "    else:\n",
        "        downloaded.GetContentFile('label.csv')\n",
        "        file=pd.read_csv('label.csv')\n",
        "        return file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH1zKRQSsxzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images=getFile(train_link,True)\n",
        "train_label=getFile(label_link,False)\n",
        "test_images=getFile(test_link,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPVZSFunqC9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_images=pd.read_pickle(train_pickle)\n",
        "# test_images=pd.read_pickle(test_pickle)\n",
        "# train_labels=pd.read_csv(train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQO0MhPnqC9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.imshow(train_images[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_9fjWetqC9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_labels.iloc[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KVBYjqeqC9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DatasetMNIST(Dataset):\n",
        "    \n",
        "    def __init__(self, x, y, transform=None):\n",
        "        self.transform = transform\n",
        "        self.data=x\n",
        "        self.labels=y\n",
        "        self.train=True\n",
        "        if y is None:\n",
        "            self.labels=pd.DataFrame(np.zeros([len(x),2]))\n",
        "            self.train=False\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # load image as ndarray type (Height * Width * Channels)\n",
        "        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n",
        "        # in this example, i don't use ToTensor() method of torchvision.transforms\n",
        "        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n",
        "        image = self.data[index]\n",
        "        label=-1\n",
        "        if self.train is True:\n",
        "            #label = self.labels.iloc[index.item(),1]\n",
        "            label = self.labels.iloc[index,1]\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = torch.from_numpy(image)\n",
        "            \n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSpdfofKqC9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform=transforms.ToTensor()\n",
        "train_image=DatasetMNIST(train_images,train_label,transform)\n",
        "train_size = int(0.8 * len(train_image))\n",
        "train,valid=torch.utils.data.dataset.random_split(train_image,[train_size,len(train_image)-train_size])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21Yv9uvAqC9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=200\n",
        "\n",
        "train_loader=torch.utils.data.DataLoader(train,batch_size=BATCH_SIZE,shuffle=True)\n",
        "valid_loader=torch.utils.data.DataLoader(valid,batch_size=BATCH_SIZE,shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_IL78PfqC9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self,filter_size=3,padding_size=1,stride_size=1):\n",
        "        super(CNN,self).__init__()\n",
        "        self.step1=nn.Sequential(\n",
        "            nn.Conv2d(1,32,kernel_size=filter_size,padding=padding_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32,32,kernel_size=filter_size,padding=padding_size),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            #\n",
        "            nn.Conv2d(32,32,kernel_size=filter_size,padding=padding_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32,32,kernel_size=filter_size,padding=padding_size),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            #\n",
        "            nn.Conv2d(32,64,kernel_size=filter_size,padding=padding_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64,64,kernel_size=filter_size,padding=padding_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64,64,kernel_size=filter_size,padding=padding_size),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "#             #\n",
        "#             nn.Conv2d(64,64,kernel_size=filter_size,padding=padding_size),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Conv2d(64,64,kernel_size=filter_size,padding=padding_size),\n",
        "#             nn.ReLU(),\n",
        "#             nn.Conv2d(64,64,kernel_size=filter_size,padding=padding_size),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(2),\n",
        "            #\n",
        "#             nn.Linear(4*4*64,4*4*64),\n",
        "        )\n",
        "        self.step2=nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(16*16*64,4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096,256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256,10),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "    \n",
        "    def forward(self,x):\n",
        "        out=self.step1(x)\n",
        "        out=out.view(out.size(0), -1)\n",
        "        out=self.step2(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niUIzDXDqC9g",
        "colab_type": "code",
        "outputId": "005a5f18-2160-4892-c350-1e58d5ccc14e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "cnn=CNN()\n",
        "use_gpu=torch.cuda.is_available()\n",
        "print(\"GPU Available:{}\".format(use_gpu))\n",
        "if use_gpu:\n",
        "    cnn.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU Available:True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xkl8oFMqC9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion=nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U-WDP0QqC9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainCNN(epoch, model,train_loader,optimizer):\n",
        "    model.train()\n",
        "\n",
        "    total_loss=0;\n",
        "    correct=0;\n",
        "\n",
        "    for i, (image,label) in enumerate(train_loader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    #images=image.view(-1,28*28)\n",
        "\n",
        "        image=image.unsqueeze_(0)\n",
        "        image=image.permute(1, 0, 2,3)\n",
        "\n",
        "        if use_gpu:\n",
        "            image=image.cuda()\n",
        "            label=label.cuda()\n",
        "\n",
        "        prediction=model(image)\n",
        "\n",
        "        loss=criterion(prediction,label)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss+=loss\n",
        "        pred_classes = prediction.data.max(1,keepdim=True)[1]\n",
        "        correct += pred_classes.eq(label.data.view_as(pred_classes)).sum().double()\n",
        "\n",
        "    mean_loss=total_loss/len(train_loader.dataset)\n",
        "    acc=correct/len(train_loader.dataset)\n",
        "\n",
        "    print('Train Epoch: {}   Avg_Loss: {:.5f}   Acc: {}/{} ({:.3f}%)'.format(\n",
        "        epoch, mean_loss, correct, len(train_loader.dataset),\n",
        "        100. * acc))\n",
        "\n",
        "    return mean_loss, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCobV5kcqC9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evalCNN(model,eval_loader):\n",
        "  \n",
        "    model.eval()\n",
        "\n",
        "    total_loss=0\n",
        "    correct=0\n",
        "\n",
        "    for i, (image,label) in enumerate(eval_loader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    #images=image.view(-1,28*28)\n",
        "\n",
        "        image=image.unsqueeze_(0)\n",
        "        image=image.permute(1, 0, 2,3)\n",
        "\n",
        "        if use_gpu:\n",
        "            image=image.cuda()\n",
        "            label=label.cuda()\n",
        "\n",
        "        prediction=model(image)\n",
        "\n",
        "        loss=criterion(prediction,label)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss+=loss\n",
        "\n",
        "        pred_classes=prediction.data.max(1,keepdim=True)[1]\n",
        "\n",
        "        correct+=pred_classes.eq(label.data.view_as(pred_classes)).sum().double()\n",
        "\n",
        "    mean_loss=total_loss/len(eval_loader.dataset)\n",
        "    acc=correct/len(eval_loader.dataset)\n",
        "\n",
        "    print('Eval:  Avg_Loss: {:.5f}   Acc: {}/{} ({:.3f}%)'.format(\n",
        "        mean_loss, correct, len(eval_loader.dataset),\n",
        "        100. *acc)) \n",
        "\n",
        "    return mean_loss, acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QoSu-J3d8-Nf",
        "colab": {}
      },
      "source": [
        "#only evaluation\n",
        "def evalCNN(model,eval_loader):\n",
        "  \n",
        "    model.eval()\n",
        "\n",
        "    total_loss=0\n",
        "    correct=0\n",
        "\n",
        "    for i, (image,label) in enumerate(eval_loader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    #images=image.view(-1,28*28)\n",
        "\n",
        "        image=image.unsqueeze_(0)\n",
        "        image=image.permute(1, 0, 2, 3)\n",
        "\n",
        "        if use_gpu:\n",
        "            image=image.cuda()\n",
        "            label=label.cuda()\n",
        "\n",
        "        prediction=model(image)\n",
        "\n",
        "        #loss=criterion(prediction,label)\n",
        "\n",
        "        #loss.backward()\n",
        "\n",
        "        #optimizer.step()\n",
        "\n",
        "        #total_loss+=loss\n",
        "\n",
        "        pred_classes=prediction.data.max(1,keepdim=True)[1]\n",
        "\n",
        "        correct+=pred_classes.eq(label.data.view_as(pred_classes)).sum().double()\n",
        "\n",
        "    #mean_loss=total_loss/len(eval_loader.dataset)\n",
        "    acc=correct/len(eval_loader.dataset)\n",
        "\n",
        "    print('Eval:  Acc: {}/{} ({:.3f}%)'.format(\n",
        "         correct, len(eval_loader.dataset),\n",
        "        100. *acc)) \n",
        "\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVMV8twSqC9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiKMRpCMk0UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(epoch, model, path='./'):\n",
        "    \n",
        "    # file name and path \n",
        "    filename = path + 'cnn_{}.pt'.format(epoch)\n",
        "    \n",
        "    # load the model parameters \n",
        "    torch.save(model.state_dict(), filename)\n",
        "    \n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rOL8mxeqC9u",
        "colab_type": "code",
        "outputId": "88d3b705-27d7-4f9f-ddb0-4ef769dc342c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "optimizer=optim.Adam(cnn.parameters(),lr=0.0001)\n",
        "# Number of epochs \n",
        "numEpochs = 50\n",
        "\n",
        "# checkpoint frequency \n",
        "checkpoint_freq = 10\n",
        "\n",
        "# path to save the data \n",
        "path = './'\n",
        "\n",
        "# empty lists \n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "# traininng \n",
        "for epoch in range(1, numEpochs + 1):\n",
        "    \n",
        "    # train() function (see above)\n",
        "    train_loss, train_acc = trainCNN(epoch, cnn, train_loader, optimizer)\n",
        "    \n",
        "    # eval() functionn (see above)\n",
        "    #test_loss, \n",
        "    test_acc = evalCNN(cnn, valid_loader)    \n",
        "    \n",
        "    # append lists for plotting and printing \n",
        "    train_losses.append(train_loss)    \n",
        "    #test_losses.append(test_loss)\n",
        "    \n",
        "    train_accuracies.append(train_acc)    \n",
        "    test_accuracies.append(test_acc)\n",
        "    \n",
        "    # Checkpoint\n",
        "    if epoch % checkpoint_freq ==0:\n",
        "        save_model(epoch, cnn, path)\n",
        "\n",
        "# Last checkpoint\n",
        "save_model(numEpochs, cnn, path)\n",
        "    \n",
        "print(\"\\n\\n\\nOptimization ended.\\n\") "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1   Avg_Loss: 0.00763   Acc: 37455.0/40000 (93.638%)\n",
            "Eval:  Acc: 9440.0/10000 (94.400%)\n",
            "Train Epoch: 2   Avg_Loss: 0.00762   Acc: 37522.0/40000 (93.805%)\n",
            "Eval:  Acc: 9493.0/10000 (94.930%)\n",
            "Train Epoch: 3   Avg_Loss: 0.00761   Acc: 37598.0/40000 (93.995%)\n",
            "Eval:  Acc: 9512.0/10000 (95.120%)\n",
            "Train Epoch: 4   Avg_Loss: 0.00761   Acc: 37624.0/40000 (94.060%)\n",
            "Eval:  Acc: 9497.0/10000 (94.970%)\n",
            "Train Epoch: 5   Avg_Loss: 0.00760   Acc: 37648.0/40000 (94.120%)\n",
            "Eval:  Acc: 9500.0/10000 (95.000%)\n",
            "Train Epoch: 6   Avg_Loss: 0.00760   Acc: 37685.0/40000 (94.213%)\n",
            "Eval:  Acc: 9453.0/10000 (94.530%)\n",
            "Train Epoch: 7   Avg_Loss: 0.00760   Acc: 37699.0/40000 (94.248%)\n",
            "Eval:  Acc: 9440.0/10000 (94.400%)\n",
            "Train Epoch: 8   Avg_Loss: 0.00759   Acc: 37747.0/40000 (94.368%)\n",
            "Eval:  Acc: 9441.0/10000 (94.410%)\n",
            "Train Epoch: 9   Avg_Loss: 0.00759   Acc: 37774.0/40000 (94.435%)\n",
            "Eval:  Acc: 9501.0/10000 (95.010%)\n",
            "Train Epoch: 10   Avg_Loss: 0.00758   Acc: 37842.0/40000 (94.605%)\n",
            "Eval:  Acc: 9451.0/10000 (94.510%)\n",
            "Train Epoch: 11   Avg_Loss: 0.00758   Acc: 37841.0/40000 (94.603%)\n",
            "Eval:  Acc: 9455.0/10000 (94.550%)\n",
            "Train Epoch: 12   Avg_Loss: 0.00758   Acc: 37868.0/40000 (94.670%)\n",
            "Eval:  Acc: 9502.0/10000 (95.020%)\n",
            "Train Epoch: 13   Avg_Loss: 0.00758   Acc: 37809.0/40000 (94.523%)\n",
            "Eval:  Acc: 9504.0/10000 (95.040%)\n",
            "Train Epoch: 14   Avg_Loss: 0.00757   Acc: 37879.0/40000 (94.698%)\n",
            "Eval:  Acc: 9471.0/10000 (94.710%)\n",
            "Train Epoch: 15   Avg_Loss: 0.00757   Acc: 37860.0/40000 (94.650%)\n",
            "Eval:  Acc: 9502.0/10000 (95.020%)\n",
            "Train Epoch: 16   Avg_Loss: 0.00757   Acc: 37904.0/40000 (94.760%)\n",
            "Eval:  Acc: 9380.0/10000 (93.800%)\n",
            "Train Epoch: 17   Avg_Loss: 0.00757   Acc: 37908.0/40000 (94.770%)\n",
            "Eval:  Acc: 9462.0/10000 (94.620%)\n",
            "Train Epoch: 18   Avg_Loss: 0.00756   Acc: 37949.0/40000 (94.873%)\n",
            "Eval:  Acc: 9484.0/10000 (94.840%)\n",
            "Train Epoch: 19   Avg_Loss: 0.00756   Acc: 37971.0/40000 (94.928%)\n",
            "Eval:  Acc: 9437.0/10000 (94.370%)\n",
            "Train Epoch: 20   Avg_Loss: 0.00756   Acc: 37974.0/40000 (94.935%)\n",
            "Eval:  Acc: 9433.0/10000 (94.330%)\n",
            "Train Epoch: 21   Avg_Loss: 0.00757   Acc: 37923.0/40000 (94.808%)\n",
            "Eval:  Acc: 9444.0/10000 (94.440%)\n",
            "Train Epoch: 22   Avg_Loss: 0.00755   Acc: 38022.0/40000 (95.055%)\n",
            "Eval:  Acc: 9470.0/10000 (94.700%)\n",
            "Train Epoch: 23   Avg_Loss: 0.00755   Acc: 38034.0/40000 (95.085%)\n",
            "Eval:  Acc: 9485.0/10000 (94.850%)\n",
            "Train Epoch: 24   Avg_Loss: 0.00755   Acc: 38046.0/40000 (95.115%)\n",
            "Eval:  Acc: 9406.0/10000 (94.060%)\n",
            "Train Epoch: 25   Avg_Loss: 0.00755   Acc: 38063.0/40000 (95.157%)\n",
            "Eval:  Acc: 9464.0/10000 (94.640%)\n",
            "Train Epoch: 26   Avg_Loss: 0.00755   Acc: 38077.0/40000 (95.192%)\n",
            "Eval:  Acc: 9489.0/10000 (94.890%)\n",
            "Train Epoch: 27   Avg_Loss: 0.00755   Acc: 38020.0/40000 (95.050%)\n",
            "Eval:  Acc: 9431.0/10000 (94.310%)\n",
            "Train Epoch: 28   Avg_Loss: 0.00754   Acc: 38149.0/40000 (95.373%)\n",
            "Eval:  Acc: 9467.0/10000 (94.670%)\n",
            "Train Epoch: 29   Avg_Loss: 0.00754   Acc: 38166.0/40000 (95.415%)\n",
            "Eval:  Acc: 9484.0/10000 (94.840%)\n",
            "Train Epoch: 30   Avg_Loss: 0.00754   Acc: 38128.0/40000 (95.320%)\n",
            "Eval:  Acc: 9477.0/10000 (94.770%)\n",
            "Train Epoch: 31   Avg_Loss: 0.00754   Acc: 38173.0/40000 (95.433%)\n",
            "Eval:  Acc: 9506.0/10000 (95.060%)\n",
            "Train Epoch: 32   Avg_Loss: 0.00753   Acc: 38234.0/40000 (95.585%)\n",
            "Eval:  Acc: 9472.0/10000 (94.720%)\n",
            "Train Epoch: 33   Avg_Loss: 0.00752   Acc: 38324.0/40000 (95.810%)\n",
            "Eval:  Acc: 9453.0/10000 (94.530%)\n",
            "Train Epoch: 34   Avg_Loss: 0.00752   Acc: 38321.0/40000 (95.802%)\n",
            "Eval:  Acc: 9452.0/10000 (94.520%)\n",
            "Train Epoch: 35   Avg_Loss: 0.00752   Acc: 38303.0/40000 (95.758%)\n",
            "Eval:  Acc: 9357.0/10000 (93.570%)\n",
            "Train Epoch: 36   Avg_Loss: 0.00751   Acc: 38392.0/40000 (95.980%)\n",
            "Eval:  Acc: 9478.0/10000 (94.780%)\n",
            "Train Epoch: 37   Avg_Loss: 0.00750   Acc: 38481.0/40000 (96.203%)\n",
            "Eval:  Acc: 9488.0/10000 (94.880%)\n",
            "Train Epoch: 38   Avg_Loss: 0.00751   Acc: 38389.0/40000 (95.973%)\n",
            "Eval:  Acc: 9462.0/10000 (94.620%)\n",
            "Train Epoch: 39   Avg_Loss: 0.00749   Acc: 38547.0/40000 (96.368%)\n",
            "Eval:  Acc: 9474.0/10000 (94.740%)\n",
            "Train Epoch: 40   Avg_Loss: 0.00749   Acc: 38577.0/40000 (96.443%)\n",
            "Eval:  Acc: 9430.0/10000 (94.300%)\n",
            "Train Epoch: 41   Avg_Loss: 0.00748   Acc: 38645.0/40000 (96.612%)\n",
            "Eval:  Acc: 9447.0/10000 (94.470%)\n",
            "Train Epoch: 42   Avg_Loss: 0.00748   Acc: 38619.0/40000 (96.548%)\n",
            "Eval:  Acc: 9462.0/10000 (94.620%)\n",
            "Train Epoch: 43   Avg_Loss: 0.00747   Acc: 38692.0/40000 (96.730%)\n",
            "Eval:  Acc: 9427.0/10000 (94.270%)\n",
            "Train Epoch: 44   Avg_Loss: 0.00749   Acc: 38570.0/40000 (96.425%)\n",
            "Eval:  Acc: 9446.0/10000 (94.460%)\n",
            "Train Epoch: 45   Avg_Loss: 0.00747   Acc: 38732.0/40000 (96.830%)\n",
            "Eval:  Acc: 9430.0/10000 (94.300%)\n",
            "Train Epoch: 46   Avg_Loss: 0.00746   Acc: 38745.0/40000 (96.863%)\n",
            "Eval:  Acc: 9499.0/10000 (94.990%)\n",
            "Train Epoch: 47   Avg_Loss: 0.00745   Acc: 38831.0/40000 (97.078%)\n",
            "Eval:  Acc: 9482.0/10000 (94.820%)\n",
            "Train Epoch: 48   Avg_Loss: 0.00746   Acc: 38811.0/40000 (97.028%)\n",
            "Eval:  Acc: 9488.0/10000 (94.880%)\n",
            "Train Epoch: 49   Avg_Loss: 0.00746   Acc: 38795.0/40000 (96.988%)\n",
            "Eval:  Acc: 9471.0/10000 (94.710%)\n",
            "Train Epoch: 50   Avg_Loss: 0.00746   Acc: 38793.0/40000 (96.983%)\n",
            "Eval:  Acc: 9515.0/10000 (95.150%)\n",
            "\n",
            "\n",
            "\n",
            "Optimization ended.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAISfam4qC9y",
        "colab_type": "code",
        "outputId": "826308c4-dd72-4978-d367-47aa31c21e0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(train_accuracies, color=\"darkcyan\", label=\"train\")\n",
        "plt.plot(test_accuracies, color=\"tomato\",label=\"validation\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGXcigmxpgygAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Piiq5-yNSW2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test=DatasetMNIST(test_images,None,transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiubwixGT0og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loader=torch.utils.data.DataLoader(test,batch_size=BATCH_SIZE,shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4llORkUtUCdz",
        "colab_type": "code",
        "outputId": "f8ca13ab-9626-4b21-ae07-73bd3b388265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "cnn.eval()\n",
        "predictions=[]\n",
        "\n",
        "for i, (image,label) in enumerate(test_loader):\n",
        "\n",
        "    image=image.unsqueeze_(0)\n",
        "    image=image.permute(1, 0, 2,3)\n",
        "\n",
        "    if use_gpu:\n",
        "        image=image.cuda()\n",
        "        label=label.cuda()\n",
        "\n",
        "    prediction=cnn(image)\n",
        "    pred_classes=prediction.data.max(1,keepdim=True)[1]\n",
        "    predictions.append(pred_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAhMN35iTAxZ",
        "colab_type": "code",
        "outputId": "5d817f6a-9ce5-4bb5-e228-62646981ae72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(predictions[-2])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEBlgKVpTbzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results=[]\n",
        "for i in predictions:\n",
        "    for j in i:\n",
        "        results.append(j.item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psET9l0UTp47",
        "colab_type": "code",
        "outputId": "90f0888a-0b00-4fd9-8044-d26a9b945bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(results[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnHRk8XHC0N0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_y_pred_df = pd.DataFrame(results, columns=('Label',))\n",
        "test_y_pred_df.index.name = 'Id'\n",
        "file=test_y_pred_df.to_csv()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGN3eZ-OUTOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "with open('vgg_3b.csv','w') as f:\n",
        "    f.write(file)\n",
        "    \n",
        "files.download('vgg_3b.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}